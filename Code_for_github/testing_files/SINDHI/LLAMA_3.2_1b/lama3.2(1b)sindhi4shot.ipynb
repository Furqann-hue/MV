{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbde9da5-acf3-4362-bb2e-338c154d8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4624f9a-4c47-48ba-880e-726adeecc79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\" \n",
    "CSV_PATH = r\"C:\\Users\\stdFurqan\\Desktop\\Sindhi (politics)\\split_30.csv\"\n",
    "TEXT_COL = \"News Headlines\"\n",
    "LABEL_COL = \"Aspect Category\"\n",
    "LABELS = [\"Crime\", \"Sports\", \"Politics\"]\n",
    "SEED = 20\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def set_seed(seed=20):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14cca0f3-6495-4fd9-a775-6aaaa4fb4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Loading model from C:\\Users\\stdFurqan\\Downloads\\lama_models_download\\LAMA_3.2(1b) ...\n",
      "âœ… Model loaded successfully from local directory!\n"
     ]
    }
   ],
   "source": [
    "# âœ… Local path where model is stored\n",
    "MODEL_PATH = r\"C:\\Users\\stdFurqan\\Downloads\\lama_models_download\\LAMA_3.2(1b)\"\n",
    "\n",
    "print(f\"ğŸ§  Loading model from {MODEL_PATH} ...\")\n",
    "\n",
    "# âœ… Load tokenizer from local folder\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# âœ… Load model from local folder\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,   # âœ… best for 40-series\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… Model loaded successfully from local directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f991566-6386-42a9-8db2-a3701d28306d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aspect Category', 'News Headlines']\n"
     ]
    }
   ],
   "source": [
    "# --- Load dataset ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "# âœ… Clean up any extra spaces or tabs in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82e4fa59-3c52-474e-af00-3c7cfa2fe9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stdFurqan\\anaconda3\\envs\\py312\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Crime     0.5736    0.7951    0.6665      1440\n",
      "      Sports     1.0000    0.0104    0.0207      1245\n",
      "    Politics     0.6058    0.7853    0.6840      2282\n",
      "\n",
      "    accuracy                         0.5939      4967\n",
      "   macro avg     0.7265    0.5303    0.4570      4967\n",
      "weighted avg     0.6953    0.5939    0.5126      4967\n",
      "\n",
      "Accuracy: 0.5939\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "texts = df[TEXT_COL].astype(str).tolist()\n",
    "true_labels = df[LABEL_COL].astype(str).tolist()\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"You are an intelligent Sindhi language assistant. \"\n",
    "    \"Classify the following news headline into one of these categories: Crime, Sports, or Politics based on the examples below.\\n\\n\"\n",
    "    \n",
    "    \"=== Politics Examples ===\\n\"\n",
    "    \"1 Text: Ø¨Ù„ÙˆÚ†Ø³ØªØ§Ù† Û¾ Ø§ÙŠØ±Ø§Ù†ÙŠ Ø³Ø±Ø²Ù…ÙŠÙ† ØªØ§Ù† Ù»ÙŠÙ‡Ø± Ø­Ù…Ù„ÙˆØŒ Ù¾Ø§Úª ÙÙˆØ¬ Ø¬Ø§ 4 Ø¬ÙˆØ§Ù† Ø´Ù‡ÙŠØ¯\\n   Label: Politics\\n\"\n",
    "    \"2 Text: Ø³Ù¾Ø±ÙŠÙ… ÚªÙˆØ±Ù½ Û¾ Ù‚Ø±Ø¢Ù† Ù¾Ø§Úª Ø¬ÙŠ Ø­Ø§ÙØ¸ Ú©ÙŠ 20 ÙˆØ§ÚŒÙˆ Ù†Ù…Ø¨Ø± ÚÙŠÚ» Ø¨Ø§Ø¨Øª Ù¾Ø§Ú»Ù…Ø±Ø§Ø¯ÙŠ Ù†ÙˆÙ½ÙŠØ³ Û¾ Ø¬Ø³Ù½Ø³ Ù‚Ø§Ø¶ÙŠ ÙØ§Ø¦Ø² Ø¹ÙŠØ³ÙŠÙ° Ø¬ÙŠ Ø³Ø±Ø¨Ø±Ø§Ù‡ÙŠ Û¾ 3 Ø±ÚªÙ†ÙŠ Ø®Ø§Øµ Ø¨Ø¦Ù†Ú† ÙÙŠØµÙ„Ùˆ Ø¬Ø§Ø±ÙŠ ÚªÙŠÙˆ\\n   Label: Politics\\n\"\n",
    "    \"3 Text: ÙˆØ§Ø¶Ø­ Ø±Ù‡ÙŠ ØªÙ‡ ÚªÙŠØ±ÙˆÙ„ Ø¦ÙŠ Ù†Ù‡ Ù¾Ø± ÚªÙŠØªØ±ÙŠÙ† Ø¦ÙŠ Ø¹ÙˆØ±ØªÙ† Ø§Ú³ÙˆÚ»ÙŠ Ø¢Ù…Ø±ÙŠÚªÙŠ ØµØ¯Ø± ØªÙŠ Ø¬Ù†Ø³ÙŠ ÚØ§ÚØ§Ø¦ÙŠ Û¾ Ù…Ù„ÙˆØ« Ù‡Ø¬Ú» Ø¬Ø§ Ø§Ù„Ø²Ø§Ù… Ù„Ú³Ø§ÙŠØ§ Ø¢Ù‡Ù†.\\n   Label: Politics\\n\"\n",
    "    \"4 Text: Ù¾ÙŠØ§Ø¯Ù„ Ù‚Ø§ÙÙ„ÙŠ Ø¬ÙŠ Ú€Ø±Ù¾ÙˆØ± Ø¢Ø¬ÙŠØ§Ù† ÚªØ±ÙŠ Ù…Ù¿Ù† Ú¯Ù„Ù† Ø¬ÙŠ ÙˆØ±Ú©Ø§ ÚªØ¦ÙŠ ÙˆØ¦ÙŠ.\\n   Label: Politics\\n\\n\"\n",
    "\n",
    "    \"=== Sports Examples ===\\n\"\n",
    "    \"5 Text: Ù†ÙŠÙ¾Ø§Ù„ Ø¬ÙŠ ÚªØ±ÚªÙŠÙ½ Ù…ÙŠÚ† ÚŠÙŠ Ø§ÙŠÙ„ Ø§ÙŠØ³ Ù…ÙŠÙ¿ÚŠ ØªØ­Øª ÙˆÙ† ÚŠÙŠ Û¾ 9 ÙˆÚªÙŠÙ½Ù† ØªÙŠ ÙŠÙˆ Ø§ÙŠ Ø§ÙŠ Ø¬ÙŠ Ù½ÙŠÙ… Ú©ÙŠ Ø´ÚªØ³Øª ÚØ¦ÙŠ Ú‡ÚÙŠ Ø¢Ù‡ÙŠ\\n   Label: Sports\\n\"\n",
    "    \"6 Text: Ù‡ÙˆÚØ§Ù†Ù‡Ù† Ù»Ø¦ÙŠ Ø³ÙŠÙ…ÙŠ ÙØ§Ø¦Ù†Ù„ Û¾ ÙˆØ±ÙŠ Ø¢Ø±ÙŠØ§Ù†Ø§ Ø³ÙŠØ¨Ø§Ù„ÙŠÙ†ÚªØ§ ÙŠÙˆÙ†Ø§Ù† Ø¬ÙŠ Ù…Ø§Ø±ÙŠØ§ Ø³ÚªØ§Ø±ÙŠ Ú©ÙŠ Ø´ÚªØ³Øª ÚØ¦ÙŠ ÙØ§Ø¦Ù†Ù„ Û¾ Ø¬Ú³Ù‡Ù‡ ÙºØ§Ù‡ÙŠ Ø¢Ù‡ÙŠØŒ Ù‡Ø§Ú» ÙØ§Ø¦Ù†Ù„ Û¾ Ø¢Ø±ÙŠØ§Ù†Ø§ Ø³ÙŠØ¨Ø§Ù„ÙŠÙ†ÚªØ§ Û½ Ø§ÙŠÙ„Ø§Ù†Ø§ Ø±ÙŠØ¨Ø§ÚªÙ†Ø§ Ø¢Ù…Ù‡ÙˆÙ† Ø³Ø§Ù…Ù‡ÙˆÙ† Ù¿ÙŠÙ†Ø¯ÙŠÙˆÙ†.\\n   Label: Sports\\n\"\n",
    "    \"7 Text: Ø¬ÚÙ‡Ù† ØªÚ¾ Ø³Ø±ÙŠÙ„Ù†ÚªØ§ ÙˆÙŠÙ…Ù† Ø¬ÙŠ Ù½ÙŠÙ… 19 Ø§ÙˆÙˆØ± Û¾ Ø±Ú³Ùˆ 3 ÙˆÚªÙŠÙ½Ù† Ø¬ÙŠ Ù†Ù‚ØµØ§Ù† ØªÙŠ Ù‡Ø¯Ù Ù¾ÙˆØ±Ùˆ ÚªØ±ÙŠ ÚªØ§Ù…ÙŠØ§Ø¨ÙŠ Ù…Ø§Ú»ÙŠ ÙˆØ±ØªÙŠØŒ Ø¬Ù† Û¾ Ú†Ù…Ø§Ø±ÙŠ Ø§ØªØ§Ù¾Ù½Ùˆ 33ØŒ Ù‡Ø±Ø´ÙŠÙ¿Ø§ Ø³Ù…Ø§Ø±Ø§ÙˆÚªØ±Ù…Ø§ 29ØŒ ÚªÙˆÙŠØ´Ø§ ÚŠÙ„Ù‡Ø§Ø±ÙŠ 20 Ø±Ù†Ø³Ù† Ø³Ø§Ù† Ù†Ù…Ø§ÙŠØ§Ù† Ø±Ù‡ÙŠÙˆÙ†\\n   Label: Sports\\n\"\n",
    "    \"8 Text: ÚªØ±Ø³Ù½ÙŠØ§Ù†Ùˆ Ø±ÙˆÙ†Ø§Ù„ÚŠÙˆ 2023Ø¹ Ø¯ÙˆØ±Ø§Ù† 38 Ú¯ÙˆÙ„ ÚªØ±ÙŠ Ø³Ú€Ù†ÙŠ Ú©Ø§Ù† Ø§Ú³ÙŠØ§Ù† Ù†ÚªØ±ÙŠ ÙˆÙŠÙˆ\\n   Label: Sports\\n\\n\"\n",
    "\n",
    "    \"=== Crime Examples ===\\n\"\n",
    "    \"9 Text: Ù¾Ø± Ú¯ÚÙŠÙ„ Ù‚ÙˆÙ…Ù† Ø¬ÙŠ Ù‡Úª Ø¨ÙŠØ§Ù† Û¾ Ú†ÙŠÙˆ ÙˆÙŠÙˆ Ø¢Ù‡ÙŠ ØªÙ‡ Ù…ÙˆØª Ø¬ÙŠ Ø³Ø²Ø§ Ù…Ø§Ú»ÙŠÙ†Ø¯Ú™Ù† Ø¬Ùˆ Ø§ØµÙ„ Ø§Ù†Ú¯ Ø§Ù† Ú©Ø§Ù† ÙˆÚŒÙŠÚª Ø¢Ù‡ÙŠ.\\n   Label: Crime\\n\"\n",
    "    \"10 Text: Ù‡Úª Ø¹ÙˆØ±Øª Ú©ÙŠ Ø³Ù†Ø¯Ø³ ÚŒÙŠØ¡Ù Ø³Ù…ÙŠØª ÚÙˆÙ‡Ø§Ø±ÙŠ Ø§ØºÙˆØ§ ÚªØ±ÙŠ ÙˆÙŠØ§.\\n   Label: Crime\\n\"\n",
    "    \"11 Text: Ù¾Ø±ÚÙŠÙ‡ÙŠ Ù…ÙŠÚŠÙŠØ§ Ù…ÙˆØ¬Ø¨ Ø§Ù† Ú³Ø§Ù„Ù‡Ù‡ Ø¬Ùˆ Ø§Ù†ÚªØ´Ø§Ù Ù‡Úª Ø§ÙŠØ±Ø§Ù†ÙŠ Ù†Ø§Ø¦Ø¨ ÙˆØ²ÙŠØ± ÙŠÙˆÙ†Ø³ Ù¾Ù†Ø§Ù‡ÙŠ ÚªÙŠÙˆ Ø¢Ù‡ÙŠØŒ Ø¬Ù†Ù‡Ù† Ú†ÙŠÙˆ Ø¢Ù‡ÙŠ ØªÙ‡ Ø§ÙŠØ±Ø§Ù† Û¾ Ø§Ø³ÚªÙˆÙ„ Ø¬ÙŠ Ú‡ÙˆÚªØ±ÙŠÙ† Ú©ÙŠ Ø²Ù‡Ø± ÚÙ†Ùˆ ÙˆÙŠÙˆ\\n   Label: Crime\\n\"\n",
    "    \"12 Text: Ú³Ú™Ù‡ÙŠ Ø®Ø¯Ø§Ø¨Ø®Ø´ Ú©ÙˆØ³Ùˆ Û¾ Ù†ÙŠÙ†Ú¯Ø±ÙŠ Ø¬ÙŠ Ù‚ØªÙ„ Ø¬Ùˆ Ø§Ù„Ø²Ø§Ù….\\n   Label: Crime\\n\\n\"\n",
    "\n",
    "    \"Reply with only one word: Politics, Sports, or Crime.\\n\"\n",
    "    \"Now classify the following text in the same way.\\n\\n\"\n",
    "    \"Text: {text}\\n\\n\"\n",
    "    \"Label:\"\n",
    ")\n",
    "\n",
    "pattern = re.compile(r\"\\b(Politics|Sports|Crime)\\b\", re.IGNORECASE)\n",
    "\n",
    "def extract_label(output):\n",
    "    m = pattern.search(output)\n",
    "    return m.group(1).capitalize() if m else \"Unknown\"\n",
    "\n",
    "pred_labels = []\n",
    "batch_size = 4  # smaller batch to fit in T4 VRAM\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    prompts = [PROMPT_TEMPLATE.format(text=t) for t in batch]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=6,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            top_p=1.0,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    for prompt, full_out in zip(prompts, decoded):\n",
    "        gen = full_out[len(prompt):].strip() if full_out.startswith(prompt) else full_out\n",
    "        pred_labels.append(extract_label(gen))\n",
    "\n",
    "# --- Evaluation ---\n",
    "report = classification_report(true_labels, pred_labels, labels=LABELS, digits=4, zero_division=0)\n",
    "acc = accuracy_score(true_labels, pred_labels)\n",
    "print(\"\\nğŸ“Š Classification Report:\\n\")\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae303ed-0880-47d6-8bda-3d52bf925761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
