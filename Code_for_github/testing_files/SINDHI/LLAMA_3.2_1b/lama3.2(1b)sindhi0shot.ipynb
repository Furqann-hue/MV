{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1522027-139c-4e56-82ca-712a94b789c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43022d5f-f0f1-4ecf-b453-e6f256c1999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"meta-llama/Llama-3.2-1B-Instruct\" \n",
    "CSV_PATH = r\"C:\\Users\\stdFurqan\\Desktop\\Sindhi (politics)\\split_30.csv\"\n",
    "TEXT_COL = \"News Headlines\"\n",
    "LABEL_COL = \"Aspect Category\"\n",
    "LABELS = [\"Crime\", \"Sports\", \"Politics\"]\n",
    "SEED = 20\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# --- Reproducibility ---\n",
    "def set_seed(seed=20):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adfb1f-c6db-4b45-8de0-4b799ce49f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Local path where model is stored\n",
    "MODEL_PATH = r\"C:\\Users\\stdFurqan\\Downloads\\lama_models_download\\LAMA_3.2(1b)\"\n",
    "\n",
    "print(f\"ðŸ§  Loading model from {MODEL_PATH} ...\")\n",
    "\n",
    "# âœ… Load tokenizer from local folder\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# âœ… Load model from local folder\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.bfloat16,   # âœ… best for 40-series\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… Model loaded successfully from local directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7826cf1c-0542-42f4-8415-bad01c575e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Load dataset ---\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "texts = df[TEXT_COL].astype(str).tolist()\n",
    "true_labels = df[LABEL_COL].astype(str).tolist()\n",
    "\n",
    "PROMPT_TEMPLATE = (\n",
    "    \"Classify the following news headline into one of these categories: Crime, Sports, or Politics.\\n\"\n",
    "    \"Reply with only one word: Crime, Sports, or Politics.\\n\\n\"\n",
    "    \"Headline: {text}\\n\\nLabel:\"\n",
    ")\n",
    "\n",
    "pattern = re.compile(r\"\\b(Crime|Sports|Politics)\\b\", re.IGNORECASE)\n",
    "\n",
    "def extract_label(output):\n",
    "    m = pattern.search(output)\n",
    "    return m.group(1).capitalize() if m else \"Unknown\"\n",
    "\n",
    "pred_labels = []\n",
    "batch_size = 4  # smaller batch to fit in T4 VRAM\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    prompts = [PROMPT_TEMPLATE.format(text=t) for t in batch]\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=6,\n",
    "            do_sample=False,\n",
    "            temperature=0.0,\n",
    "            top_p=1.0,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    for prompt, full_out in zip(prompts, decoded):\n",
    "        gen = full_out[len(prompt):].strip() if full_out.startswith(prompt) else full_out\n",
    "        pred_labels.append(extract_label(gen))\n",
    "\n",
    "# --- Evaluation ---\n",
    "report = classification_report(true_labels, pred_labels, labels=LABELS, digits=4, zero_division=0)\n",
    "acc = accuracy_score(true_labels, pred_labels)\n",
    "print(\"\\nðŸ“Š Classification Report:\\n\")\n",
    "print(report)\n",
    "print(f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4a0b8-ef31-4b15-ab08-1bbca3afe993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
